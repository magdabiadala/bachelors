{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.preprocessing import normalize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import svm\n",
    "from random import randint, random, shuffle\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN = 137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funkcje do przetwarzania danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    people = []\n",
    "    for i in range(1,16):\n",
    "    # omijam osobę 5\n",
    "        if i != 5:\n",
    "#             person = np.genfromtxt('ICA/Features_os' + str(i) + '.csv', delimiter=',')\n",
    "            person = np.genfromtxt('MCSB_dane/Features_os' + str(i) + '.csv', delimiter=',')\n",
    "            # delete first row with electrode/signal names\n",
    "            person = np.delete(person, 0, 0)\n",
    "            people.append(person)\n",
    "#   za każdym razem inne osoby służą do treningu, a inne do testu\n",
    "    shuffle(people)\n",
    "    rest = np.concatenate((people[0:12]))\n",
    "    test = np.concatenate((people[12:]))\n",
    "    np.random.shuffle(rest)\n",
    "    np.random.shuffle(test)\n",
    "    return rest, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data2():\n",
    "    people = []\n",
    "    for i in range(15):\n",
    "    # omijam osobę 5\n",
    "        if i != 4:\n",
    "            person = np.genfromtxt('nothing/Features_os' + str(i) + '.csv', delimiter=',')\n",
    "            # delete first row with electrode/signal names\n",
    "            person = np.delete(person, 0, 0)\n",
    "            people.append(person)\n",
    "#   za każdym razem inne osoby służą do treningu, a inne do testu\n",
    "    shuffle(people)\n",
    "    rest = np.concatenate((people[0:12]))\n",
    "    test = np.concatenate((people[12:]))\n",
    "    np.random.shuffle(rest)\n",
    "    np.random.shuffle(test)\n",
    "    return rest, test\n",
    "\n",
    "# r, t = load_data2()\n",
    "# idx = [True if x<34 or x==136 else False for x in range(137)]\n",
    "# r = r[:,idx]\n",
    "# t = t[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcje pomocnicze zmieniające wartość w ostatniej kolumnie arraya\n",
    "\n",
    "def change_4_to_0(arr):\n",
    "    if arr[-1] == 4:\n",
    "        arr[-1] = 0\n",
    "        \n",
    "def change_5_to_1(arr):\n",
    "    if arr[-1] == 5:\n",
    "        arr[-1] = 1\n",
    "        \n",
    "def change_5_to_0(arr):\n",
    "    if arr[-1] == 5:\n",
    "        arr[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja zmieniająca wartość w ostatniej kolumnie w zależności od tego czy klasyfikator ma odróżniać:\n",
    "# - błędy interfejsu od udanych kliknięć i błędów użytkownika (do bci uczącego się)\n",
    "# - błędy interfejsu i błędy użytkownika od udanych kliknięć (do bci cofającego błędy)\n",
    "\n",
    "def recode_data(data, bci_type):\n",
    "    if bci_type == 'learning':\n",
    "#         błędy użytkownika (5) traktowane jak sukcesy\n",
    "        np.apply_along_axis(change_4_to_0, 1, data)\n",
    "        np.apply_along_axis(change_5_to_1, 1, data)\n",
    "    elif bci_type == 'withdraw':\n",
    "#         błędy użytkownika (5) traktowane jak porażki\n",
    "        np.apply_along_axis(change_4_to_0, 1, data)\n",
    "        np.apply_along_axis(change_5_to_0, 1, data)\n",
    "    else:\n",
    "        print('wrong type')\n",
    "    \n",
    "# recode_data(rest, 'withdraw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ostatecznie się nie udało\n",
    "\n",
    "def coefficient_of_variation(arr):\n",
    "    return np.std(arr)/np.mean(arr)\n",
    "\n",
    "def remove_low_variation(rest, test, treshold):\n",
    "#     print(rest)\n",
    "    n_rest_rows = rest.shape[0]\n",
    "    n_test_rows = test.shape[0]\n",
    "    rest_labels = rest[:,-1]\n",
    "    test_labels = test[:,-1]\n",
    "    coef_of_var = np.apply_along_axis(coefficient_of_variation, 0, rest[:,:-1])\n",
    "#     print(coef_of_var)\n",
    "    sorted_arr = np.sort(coef_of_var)\n",
    "#     print(sorted_arr)\n",
    "#     print(sorted_arr[-treshold:])\n",
    "#     print(sorted_arr[-treshold])\n",
    "    smallest_val = sorted_arr[-treshold]\n",
    "#     print(np.where(coef_of_var >= smallest_val))\n",
    "    idx = np.where(coef_of_var >= smallest_val)\n",
    "#     print(rest[:,idx])\n",
    "    rest = np.hstack((rest[:,idx].reshape(n_rest_rows,treshold), np.expand_dims(rest_labels, axis=1)))\n",
    "    test = np.hstack((test[:,idx].reshape(n_test_rows,treshold), np.expand_dims(test_labels, axis=1)))\n",
    "    return rest, test\n",
    "\n",
    "# np.expand_dims(rest_labels, axis=1)\n",
    "\n",
    "# b = np.array([[1,2,3,4], [4,5,6,7], [7,8,9,2], [1,2,3,3], [4,5,6,1], [7,8,9,9]])\n",
    "# c = np.array([[3,4,7,0], [2,1,2,2]])\n",
    "\n",
    "# result = remove_low_variation(b, c, 2)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja standaryzująca każdą z cech tak, aby miała średnią = 0 i wariancję = 1\n",
    "\n",
    "def scale_data(rest, test):\n",
    "    scaler = preprocessing.StandardScaler().fit(rest[:,:-1])\n",
    "    scaled_rest = scaler.transform(rest[:,:-1])\n",
    "    scaled_test = scaler.transform(test[:,:-1])\n",
    "    rest = np.hstack((scaled_rest, np.expand_dims(rest[:,-1], axis=1)))\n",
    "    test = np.hstack((scaled_test, np.expand_dims(test[:,-1], axis=1)))\n",
    "    return rest, test\n",
    "    \n",
    "# rest, test = scale_data(rest, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyrównywanie liczby wierszy dla każdej z klas\n",
    "# zwraca dane uporządkowane klasami, ale to nie problem, bo potem i tak są one mieszane przed treningiem i testem\n",
    "\n",
    "def downsample(data):\n",
    "    # Indicies of each class' observations\n",
    "    i_class0 = np.where(data[:,-1] == 0)[0]\n",
    "    i_class1 = np.where(data[:,-1] == 1)[0]\n",
    "\n",
    "    # Number of observations in each class\n",
    "    n_class0 = len(i_class0)\n",
    "    n_class1 = len(i_class1)\n",
    "\n",
    "    # For every observation of class 0, randomly sample from class 1 without replacement\n",
    "    i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False)\n",
    "\n",
    "    # Join together class 0's target vector with the downsampled class 1's target vector\n",
    "    joined = np.vstack((data[i_class0], data[i_class1_downsampled]))\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funkcje do algorytmu genetycznego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja tworząca pierwsze pokolenie\n",
    "# jedynki oznaczają cechy sygnału przekazywane do klasyfikatora\n",
    "\n",
    "def first_gen(generation_size):\n",
    "    first_gen = np.random.randint(2, size=(generation_size,LEN-1))\n",
    "    return first_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja oceniająca przystosowanie danego osobnika\n",
    "\n",
    "def eval_ind_knn(individual, X_train, X_test, y_train, y_test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    neigh.fit(X_train[:,individual==1], y_train)\n",
    "    accuracy = neigh.score(X_test[:,individual==1], y_test)\n",
    "#     print(\"accuracy: \",accuracy)\n",
    "#     print(\"zeros: \", np.count_nonzero(individual==0))\n",
    "    return (accuracy*np.count_nonzero(individual==0))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ind_svm(individual, X_train, X_test, y_train, y_test):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train[:,individual==1], y_train)\n",
    "    accuracy = clf.score(X_test[:,individual==1], y_test)\n",
    "#     print(\"accuracy: \",accuracy)\n",
    "#     print(\"zeros: \", np.count_nonzero(individual==0))\n",
    "    return (accuracy*np.count_nonzero(individual==0))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja oceniająca całe pokolenie\n",
    "\n",
    "def evaluation(X_train, X_test, y_train, y_test, generation, classifier):\n",
    "#     X_train, X_test, y_train, y_test = X_train, X_test, y_train, y_test\n",
    "    if classifier == 'knn':\n",
    "        gen_fitness = np.apply_along_axis(eval_ind_knn, 1, generation, X_train, X_test, y_train, y_test)\n",
    "    elif classifier == 'svm':\n",
    "        gen_fitness = np.apply_along_axis(eval_ind_svm, 1, generation, X_train, X_test, y_train, y_test)\n",
    "    else:\n",
    "        print('wrong classifier')\n",
    "#     print(gen_fitness)\n",
    "    best_ind = generation[np.argmax(gen_fitness)]\n",
    "    best_fit = max(gen_fitness)\n",
    "    mean_fit = np.mean(gen_fitness)\n",
    "#     print(\"fitness\", best_fit)\n",
    "#     print(\"mean_fitness\", mean_fit)\n",
    "    best_acc = (best_fit-1)/np.count_nonzero(best_ind==0)\n",
    "#     mean_acc = ()\n",
    "#     print('acc',best_acc)\n",
    "#     print(\"accuracy: \",best_fit/np.count_nonzero(best_ind==0))\n",
    "#     print(\"ones: \", np.count_nonzero(best_ind))\n",
    "#          gen_fitness,   local_n_of_zeros,      global_best_fitness,     global_best_accuracy,       best_individual\n",
    "    return gen_fitness, np.count_nonzero(best_ind==0), best_fit, (best_fit-1)/np.count_nonzero(best_ind==0), best_ind\n",
    "#     return gen_fitness, np.count_nonzero(best_ind==0), best_fit, (best_fit-1)/np.count_nonzero(best_ind==0), best_ind, mean_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ruletka\n",
    "\n",
    "def roulette(generation, gen_fitness, generation_size):\n",
    "    gen_fitness /= sum(gen_fitness)\n",
    "    survivors = np.random.choice(generation_size, generation_size, p=gen_fitness)\n",
    "    return generation[survivors,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja krzyżująca osobniki\n",
    "\n",
    "def crossover(survivors, generation_size, crossover_prob):\n",
    "# czy można się pozbyć tego fora?\n",
    "    for i in range(0,generation_size,2):\n",
    "        if np.random.rand() <= crossover_prob:\n",
    "            cut = np.random.randint(1,LEN-2)\n",
    "            temp = survivors[1,:cut].copy()\n",
    "            survivors[1,:cut] = survivors[0,:cut]\n",
    "            survivors[0,:cut] = temp\n",
    "    return survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja mutująca wybrane geny wybranych osobników z pokolenia\n",
    "\n",
    "def mutation(individual, mutation_prob):\n",
    "    if np.random.rand() <= mutation_prob:\n",
    "        locus = np.random.randint(0,LEN-2)\n",
    "        individual[locus] = 1-individual[locus]\n",
    "#     return ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### algorytm genetyczny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_alg(X_train, X_test, y_train, y_test, generation_size, num_of_generations, mutation_prob,\n",
    "            crossover_prob, classifier, rand_state):\n",
    "#     best_fit_list = []\n",
    "#     mean_fit_list = []\n",
    "#     best_acc_list = []\n",
    "    \n",
    "# inicjalizacja populacji (first generation)\n",
    "#     print('gen ', 0)   \n",
    "    generation = first_gen(generation_size)\n",
    "    \n",
    "# ocena przystosowania populacji\n",
    "    global_best_fitness = 0\n",
    "#     gen_fitness, local_n_of_zeros, global_best_fitness, global_best_accuracy, best_individual, mean_fit = evaluation(X_train, X_test,y_train, y_test, generation, classifier)\n",
    "    gen_fitness, local_n_of_zeros, global_best_fitness, global_best_accuracy, best_individual = evaluation(X_train, X_test,y_train, y_test, generation, classifier)\n",
    "#     \n",
    "#     best_fit_list.append(global_best_fitness)\n",
    "#     mean_fit_list.append(mean_fit)\n",
    "#     best_acc_list.append(global_best_accuracy)\n",
    "#     \n",
    "#     print('local ',local_best_fitness)\n",
    "#     print('num of zeros ', local_n_of_zeros)\n",
    "#     global_best_fitness = local_best_fitness\n",
    "#     global_best_accuracy = local_best_accuracy\n",
    "#     print(global_best_fitness)\n",
    "        \n",
    "# główna pętla programu\n",
    "    for i in range(num_of_generations):\n",
    "#         print('gen ', i+1)   \n",
    "# ruletka\n",
    "        survivors = roulette(generation, gen_fitness, generation_size)\n",
    "# krzyżowanie\n",
    "        descendants = crossover(survivors, generation_size, crossover_prob)  \n",
    "# mutacje\n",
    "        np.apply_along_axis(mutation, 1, descendants, mutation_prob)\n",
    "# ocena\n",
    "#         gen_fitness, local_n_of_zeros, local_best_fitness, local_best_accuracy, local_best_individual, mean_fit = evaluation(X_train, X_test, y_train, y_test, descendants, classifier)\n",
    "        gen_fitness, local_n_of_zeros, local_best_fitness, local_best_accuracy, local_best_individual = evaluation(X_train, X_test,y_train, y_test, generation, classifier)\n",
    "\n",
    "#         print('local ',local_best_fitness)\n",
    "#         print('num of zeros ', local_n_of_zeros)\n",
    "        if local_best_fitness > global_best_fitness:\n",
    "            global_best_fitness = local_best_fitness\n",
    "            global_best_accuracy = local_best_accuracy\n",
    "            best_individual = local_best_individual\n",
    "#         print(global_best_fitness)\n",
    "        #         \n",
    "#         best_fit_list.append(global_best_fitness)\n",
    "#         mean_fit_list.append(mean_fit)\n",
    "#         best_acc_list.append(local_best_accuracy)\n",
    "\n",
    "\n",
    "        generation = descendants\n",
    "#     return global_best_fitness, global_best_accuracy, best_individual, best_fit_list, mean_fit_list, best_acc_list\n",
    "    return global_best_fitness, global_best_accuracy, best_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funkcje do tworzenia wykresów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generation_size, num_of_generations, crossover_prob, mutation_prob, classifier,\n",
    "#          bci_type, coef_of_var, treshold, scaling, downsampling, rand_state\n",
    "# bci_type='learning'\n",
    "# rest, end_test = load_data()\n",
    "# recode_data(rest, bci_type)\n",
    "# recode_data(end_test, bci_type)\n",
    "# rest, end_test = scale_data(rest, end_test)\n",
    "# rest = downsample(rest)\n",
    "# end_test = downsample(end_test)\n",
    "# # kfold\n",
    "# kf = KFold(n_splits=20, shuffle=True, random_state=4)\n",
    "# j = 0\n",
    "# best_fit_data = []\n",
    "# mean_fit_data = []\n",
    "# best_acc_data = []\n",
    "# for train_index, test_index in kf.split(rest[:,-1]):\n",
    "#         X_train, X_test = rest[:,:-1][train_index], rest[:,:-1][test_index]\n",
    "#         y_train, y_test = rest[:,-1][train_index], rest[:,-1][test_index]\n",
    "# #         global_best_fitness, global_best_accuracy, best_individual, best_fit_list, mean_fit_list, best_acc_list= gen_alg(X_train,\n",
    "# #                                                                              X_test, y_train,\n",
    "# #                                                                              y_test,generation_size=30,\n",
    "# #                                                                              num_of_generations=400,\n",
    "# #                                                                              mutation_prob=0.01,\n",
    "# #                                                                              crossover_prob=1, classifier='knn',\n",
    "# #                                                                              rand_state=4)\n",
    "# #         print('genetic algorithm number:', j)\n",
    "#         best_fit_data.append(best_fit_list)\n",
    "#         mean_fit_data.append(mean_fit_list)\n",
    "#         best_acc_data.append(best_acc_list)\n",
    "#         j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_fit_data = np.array(best_fit_data)\n",
    "# mean_fit_data = np.array(mean_fit_data)\n",
    "# best_acc_data = np.array(best_acc_data)\n",
    "# print(best_fit_data.shape, mean_fit_data.shape, best_acc_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best_fit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_fitnesses = np.apply_along_axis(mean, 0, best_fit_data)\n",
    "# mean_fitnesses = np.apply_along_axis(mean, 0, mean_fit_data)\n",
    "# best_accuracies = np.apply_along_axis(mean, 0, best_acc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_fitnesses.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # a = np.array(best_fit_list)\n",
    "# # b = np.array(mean_fit_list)\n",
    "# # c = np.array(best_acc_list)\n",
    "# # # print(a)\n",
    "# # # print(np.array(range(c.shape[0])))\n",
    "# plt.figure(figsize=(15,5))\n",
    "# plt.xlabel('numer pokolenia')\n",
    "# plt.ylabel('dopasowanie')\n",
    "# plt.plot(np.array(range(best_fitnesses.shape[0])),best_fitnesses, label=\"najlepsze dopasowanie\")\n",
    "# plt.plot(np.array(range(mean_fitnesses.shape[0])),mean_fitnesses, label=\"średnie dopasowanie w pokoleniu\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "# plt.plot([1, 2, 3], label=\"test1\")\n",
    "# plt.plot([3, 2, 1], label=\"test2\")\n",
    "# Place a legend to the right of this smaller subplot.\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "# alltime = np.linspace(0, 500, data[0][:,0].size)\n",
    "# plt.figure(figsize=(15,5))\n",
    "# plt.xlabel('time [s]')\n",
    "# plt.ylabel('amplitude [uV]')\n",
    "# plt.plot(alltime, data[0][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,5))\n",
    "# plt.xlabel('numer pokolenia')\n",
    "# plt.ylabel('skuteczność')\n",
    "# plt.plot(np.array(range(best_accuracies.shape[0])), best_accuracies, label=\"najlepsza skuteczność w pokoleniu\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "\n",
    "# models = [np.array(best_fit_list), np.array(mean_fit_list), np.array(best_acc_list)]\n",
    "# names = ['Best fitness',\n",
    "#          'Mean fitness',\n",
    "#          'Best accuracy']\n",
    "# colors = ['red', 'steelblue', 'green']\n",
    "\n",
    "# for ii, (model, name) in enumerate(zip(models, names), 1):\n",
    "#     plt.subplot(3, 1, ii)\n",
    "#     plt.title(name)\n",
    "#     for sig, color in zip(model, colors):\n",
    "#         plt.plot(sig, color=color)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funkcja do treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# z pozostałych 80% do treningu:\n",
    "# podział na 5 grup\n",
    "\n",
    "def train(X_rest, y_rest, generation_size, num_of_generations, crossover_prob, mutation_prob, classifier, rand_state):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=rand_state)\n",
    "    alltime_best_fitness = 0\n",
    "#     alltime_best_accuracy = 0\n",
    "#     best_individual = np.array([])\n",
    "\n",
    "    for train_index, test_index in kf.split(X_rest):\n",
    "        X_train, X_test = X_rest[train_index], X_rest[test_index]\n",
    "        y_train, y_test = y_rest[train_index], y_rest[test_index]\n",
    "        global_best_fitness, global_best_accuracy, best_individual = gen_alg(X_train, X_test, y_train,\n",
    "                                                                             y_test,generation_size,\n",
    "                                                                             num_of_generations,\n",
    "                                                                             mutation_prob,\n",
    "                                                                             crossover_prob, classifier,\n",
    "                                                                             rand_state)\n",
    "#         print('fitness: ',global_best_fitness,\"\\naccuracy: \", global_best_accuracy, \"\\nindividual: \", best_individual)\n",
    "        if global_best_fitness > alltime_best_fitness:\n",
    "#             alltime_best_fitness = global_best_fitness\n",
    "#             alltime_best_accuracy = global_best_accuracy\n",
    "            alltime_best_individual = best_individual\n",
    "    return alltime_best_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funkcja przeprowadzająca test końcowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_end_test(X_end_test, y_end_test, alltime_best_individual, classifier, rand_state):\n",
    "    folds = KFold(n_splits=X_end_test.shape[0], shuffle=True)\n",
    "    if classifier == 'knn':\n",
    "        neigh3 = KNeighborsClassifier(n_neighbors=3)\n",
    "        score = cross_val_score(neigh3, X_end_test[:,alltime_best_individual==1], y_end_test, cv=folds)\n",
    "    elif classifier == 'svm':\n",
    "        clf2 = svm.SVC()\n",
    "        score = cross_val_score(clf2, X_end_test[:,alltime_best_individual==1], y_end_test, cv=folds)\n",
    "    else:\n",
    "        print('wrong classifier')\n",
    "#     print('end test score: ',score)\n",
    "    print('\\nend test score mean: ',score.mean(), '\\n')\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funkcja main i jej wykorzystanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(generation_size, num_of_generations, crossover_prob, mutation_prob, classifier,\n",
    "         bci_type, coef_of_var, treshold, scaling, downsampling, rand_state):\n",
    "    rest, end_test = load_data()\n",
    "    recode_data(rest, bci_type)\n",
    "    recode_data(end_test, bci_type)\n",
    "    if coef_of_var:\n",
    "        rest, end_test = remove_low_variation(rest, test, treshold)\n",
    "    if scaling:\n",
    "        rest, end_test = scale_data(rest, end_test)\n",
    "    if downsampling:\n",
    "        rest = downsample(rest)\n",
    "        end_test = downsample(end_test)\n",
    "    \n",
    "    alltime_best_individual = train(rest[:,:-1], rest[:,-1], generation_size, num_of_generations, \n",
    "                                    crossover_prob, mutation_prob, classifier, rand_state)\n",
    "    print(alltime_best_individual)\n",
    "    end_test_score_mean = perform_end_test(end_test[:,:-1], end_test[:,-1], alltime_best_individual, classifier, rand_state)\n",
    "    return end_test_score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2(generation_size, num_of_generations, crossover_prob, mutation_prob, classifier,\n",
    "         bci_type, coef_of_var, treshold, scaling, downsampling, rand_state):\n",
    "#     rest, end_test = load_data2()\n",
    "    \n",
    "    r, t = load_data2()\n",
    "    idx = [True if x<34 or x==136 else False for x in range(137)]\n",
    "    rest = r[:,idx]\n",
    "    end_test = t[:,idx]\n",
    "    \n",
    "    recode_data(rest, bci_type)\n",
    "    recode_data(end_test, bci_type)\n",
    "    if coef_of_var:\n",
    "        rest, end_test = remove_low_variation(rest, test, treshold)\n",
    "    if scaling:\n",
    "        rest, end_test = scale_data(rest, end_test)\n",
    "    if downsampling:\n",
    "        rest = downsample(rest)\n",
    "        end_test = downsample(end_test)\n",
    "    \n",
    "    alltime_best_individual = train(rest[:,:-1], rest[:,-1], generation_size, num_of_generations, \n",
    "                                    crossover_prob, mutation_prob, classifier, rand_state)\n",
    "    print(alltime_best_individual)\n",
    "    end_test_score_mean = perform_end_test(end_test[:,:-1], end_test[:,-1], alltime_best_individual, classifier, rand_state)\n",
    "    return end_test_score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_no_gen_alg(classifier, bci_type, scaling, downsampling, rand_state):\n",
    "    rest, end_test = load_data2()\n",
    "    recode_data(rest, bci_type)\n",
    "    recode_data(end_test, bci_type)\n",
    "    if scaling:\n",
    "        rest, end_test = scale_data(rest, end_test)\n",
    "    if downsampling:\n",
    "        rest = downsample(rest)\n",
    "        end_test = downsample(end_test)\n",
    "    individual = np.ones(136)\n",
    "#     print(individual)\n",
    "    end_test_score_mean = perform_end_test(end_test[:,:-1], end_test[:,-1], individual, classifier, rand_state)\n",
    "    return end_test_score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bci_type in ['learning','withdraw']:\n",
    "#     for classifier in ['svm','knn']:\n",
    "#         for scaling in [True, False]:\n",
    "#             result = []\n",
    "#             print('bci_type:', bci_type, ', classifier:', classifier, ', scaling:', scaling)\n",
    "#             for i in range(10):\n",
    "#                 score = main_no_gen_alg(classifier, bci_type, scaling, downsampling=True, rand_state=4)\n",
    "#                 result.append(score)\n",
    "#             print(mean(result), '\\n')\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bci_type: learning , classifier: svm , scaling: True , coef_of_var: False\n",
      "mutation_prob: 0.01 , num_of_generations: 100 , generation_size: 30 \n",
      "\n",
      "[0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0\n",
      " 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0]\n",
      "\n",
      "end test score mean:  0.9558823529411765 \n",
      "\n",
      "[1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0\n",
      " 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0]\n",
      "\n",
      "end test score mean:  0.8484848484848485 \n",
      "\n",
      "[0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0\n",
      " 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0]\n",
      "\n",
      "end test score mean:  0.967741935483871 \n",
      "\n",
      "[0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0\n",
      " 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 1 0 0\n",
      " 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1]\n",
      "\n",
      "end test score mean:  0.9821428571428571 \n",
      "\n",
      "[1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0\n",
      " 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 1 0]\n",
      "\n",
      "end test score mean:  0.631578947368421 \n",
      "\n",
      "[1 0 1 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1\n",
      " 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0\n",
      " 0 1 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.8428571428571429 \n",
      "\n",
      "[0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1\n",
      " 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.8625 \n",
      "\n",
      "[1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1\n",
      " 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1]\n",
      "\n",
      "end test score mean:  0.8611111111111112 \n",
      "\n",
      "[0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1\n",
      " 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1]\n",
      "\n",
      "end test score mean:  0.8289473684210527 \n",
      "\n",
      "[1 1 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0]\n",
      "\n",
      "end test score mean:  0.7045454545454546 \n",
      "\n",
      "[1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0]\n",
      "\n",
      "end test score mean:  0.6666666666666666 \n",
      "\n",
      "[1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.8857142857142857 \n",
      "\n",
      "[0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0\n",
      " 1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0]\n",
      "\n",
      "end test score mean:  0.9375 \n",
      "\n",
      "[0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1\n",
      " 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0\n",
      " 0 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.9487179487179487 \n",
      "\n",
      "[0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 1 1 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.9523809523809523 \n",
      "\n",
      "[1 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1\n",
      " 1 0 1 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0]\n",
      "\n",
      "end test score mean:  0.96 \n",
      "\n",
      "[0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      " 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1\n",
      " 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.9696969696969697 \n",
      "\n",
      "[0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
      " 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1\n",
      " 0 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.8518518518518519 \n",
      "\n",
      "[0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0\n",
      " 1 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1]\n",
      "\n",
      "end test score mean:  0.7857142857142857 \n",
      "\n",
      "[1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0\n",
      " 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0\n",
      " 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.8571428571428571 \n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1\n",
      " 0 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
      " 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1]\n",
      "\n",
      "end test score mean:  1.0 \n",
      "\n",
      "[1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 1 1\n",
      " 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0]\n",
      "\n",
      "end test score mean:  0.9428571428571428 \n",
      "\n",
      "[1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.7333333333333333 \n",
      "\n",
      "[0 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 1\n",
      " 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0\n",
      " 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.9193548387096774 \n",
      "\n",
      "[0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0\n",
      " 0 0 1 0 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0\n",
      " 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.8875 \n",
      "\n",
      "[0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1\n",
      " 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0\n",
      " 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.9125 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0\n",
      " 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.8695652173913043 \n",
      "\n",
      "[1 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 1 0 1 0\n",
      " 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1]\n",
      "\n",
      "end test score mean:  0.9545454545454546 \n",
      "\n",
      "[1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1\n",
      " 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1 1 0]\n",
      "\n",
      "end test score mean:  0.9142857142857143 \n",
      "\n",
      "[1 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0\n",
      " 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 1 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0]\n",
      "\n",
      "end test score mean:  0.9634146341463414 \n",
      "\n",
      "[0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 1\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1]\n",
      "\n",
      "end test score mean:  0.6744186046511628 \n",
      "\n",
      "[1 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0\n",
      " 1 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.9285714285714286 \n",
      "\n",
      "[0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1\n",
      " 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 0]\n",
      "\n",
      "end test score mean:  0.8833333333333333 \n",
      "\n",
      "[0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1\n",
      " 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0\n",
      " 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 1 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0]\n",
      "\n",
      "end test score mean:  0.8571428571428571 \n",
      "\n",
      "[1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 1 0 1 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1\n",
      " 0 1 0 0 0 0 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0\n",
      " 0 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.9821428571428571 \n",
      "\n",
      "[0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 1 1 1 0\n",
      " 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1]\n",
      "\n",
      "end test score mean:  0.016666666666666666 \n",
      "\n",
      "[0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1\n",
      " 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1\n",
      " 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0]\n",
      "\n",
      "end test score mean:  0.8714285714285714 \n",
      "\n",
      "[1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 0\n",
      " 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1 0]\n",
      "\n",
      "end test score mean:  0.8857142857142857 \n",
      "\n",
      "[1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0]\n",
      "\n",
      "end test score mean:  0.7560975609756098 \n",
      "\n",
      "[0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.925531914893617 \n",
      "\n",
      "[1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1\n",
      " 1 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0\n",
      " 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1]\n",
      "\n",
      "end test score mean:  0.9571428571428572 \n",
      "\n",
      "[0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1\n",
      " 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.8382352941176471 \n",
      "\n",
      "[0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 1 1 0\n",
      " 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.9305555555555556 \n",
      "\n",
      "[0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1\n",
      " 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.6621621621621622 \n",
      "\n",
      "[1 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1\n",
      " 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0]\n",
      "\n",
      "end test score mean:  0.6447368421052632 \n",
      "\n",
      "[1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1\n",
      " 0 1 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0]\n",
      "\n",
      "end test score mean:  0.65 \n",
      "\n",
      "[0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.7272727272727273 \n",
      "\n",
      "[0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0\n",
      " 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0\n",
      " 1 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 1]\n",
      "\n",
      "end test score mean:  0.9574468085106383 \n",
      "\n",
      "[0 1 0 1 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1\n",
      " 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0\n",
      " 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.8970588235294118 \n",
      "\n",
      "[0 1 0 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0\n",
      " 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.7702702702702703 \n",
      "\n",
      "0.8442892718539529 \n",
      "\n",
      "bci_type: withdraw , classifier: svm , scaling: True , coef_of_var: False\n",
      "mutation_prob: 0.01 , num_of_generations: 100 , generation_size: 30 \n",
      "\n",
      "[1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0\n",
      " 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 1 0 0 1 1]\n",
      "\n",
      "end test score mean:  0.6807228915662651 \n",
      "\n",
      "[0 1 0 1 1 0 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0\n",
      " 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "end test score mean:  0.8865979381443299 \n",
      "\n",
      "[1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.7701149425287356 \n",
      "\n",
      "[1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1\n",
      " 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 1]\n",
      "\n",
      "end test score mean:  0.87 \n",
      "\n",
      "[1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 1 0\n",
      " 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1\n",
      " 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 0\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      "\n",
      "end test score mean:  0.7653061224489796 \n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.9432989690721649 \n",
      "\n",
      "[1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1]\n",
      "\n",
      "end test score mean:  0.8539325842696629 \n",
      "\n",
      "[0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0\n",
      " 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 0 0\n",
      " 1 1 0 1 1 0 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0]\n",
      "\n",
      "end test score mean:  0.9431818181818182 \n",
      "\n",
      "[0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0\n",
      " 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0\n",
      " 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0]\n",
      "\n",
      "end test score mean:  0.8284313725490197 \n",
      "\n",
      "[1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1\n",
      " 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.780373831775701 \n",
      "\n",
      "[0 1 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 1\n",
      " 0 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1]\n",
      "\n",
      "end test score mean:  0.8975903614457831 \n",
      "\n",
      "[0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.7525252525252525 \n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 1 1 1 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1]\n",
      "\n",
      "end test score mean:  0.921875 \n",
      "\n",
      "[1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 1\n",
      " 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.7745098039215687 \n",
      "\n",
      "[1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0\n",
      " 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1]\n",
      "\n",
      "end test score mean:  0.8350515463917526 \n",
      "\n",
      "[1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 0\n",
      " 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.8953488372093024 \n",
      "\n",
      "[0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0]\n",
      "\n",
      "end test score mean:  0.8181818181818182 \n",
      "\n",
      "[1 0 1 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1\n",
      " 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 0]\n",
      "\n",
      "end test score mean:  0.797979797979798 \n",
      "\n",
      "[1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 0 0]\n",
      "\n",
      "end test score mean:  0.6515151515151515 \n",
      "\n",
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.88 \n",
      "\n",
      "[0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0\n",
      " 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 1 1 0]\n",
      "\n",
      "end test score mean:  0.8920454545454546 \n",
      "\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1\n",
      " 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 1 1 0 1 0\n",
      " 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0]\n",
      "\n",
      "end test score mean:  0.8908045977011494 \n",
      "\n",
      "[0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1\n",
      " 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 1 1]\n",
      "\n",
      "end test score mean:  0.8315217391304348 \n",
      "\n",
      "[1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1]\n",
      "\n",
      "end test score mean:  0.9197530864197531 \n",
      "\n",
      "[0 1 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.8820224719101124 \n",
      "\n",
      "[0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1\n",
      " 1 0 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0\n",
      " 1 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 1\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.8789473684210526 \n",
      "\n",
      "[1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 1 0\n",
      " 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1]\n",
      "\n",
      "end test score mean:  0.9550561797752809 \n",
      "\n",
      "[0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "end test score mean:  0.8969072164948454 \n",
      "\n",
      "[0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1\n",
      " 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.9012345679012346 \n",
      "\n",
      "[0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1\n",
      " 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0]\n",
      "\n",
      "end test score mean:  0.8703703703703703 \n",
      "\n",
      "[1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1\n",
      " 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1\n",
      " 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.9174757281553398 \n",
      "\n",
      "[1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 1\n",
      " 0 1 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 1]\n",
      "\n",
      "end test score mean:  0.8990384615384616 \n",
      "\n",
      "[0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 1\n",
      " 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0\n",
      " 1 0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 0 1\n",
      " 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.9044943820224719 \n",
      "\n",
      "[0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0\n",
      " 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.8902439024390244 \n",
      "\n",
      "[1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1\n",
      " 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1\n",
      " 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1]\n",
      "\n",
      "end test score mean:  0.9226804123711341 \n",
      "\n",
      "[0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0\n",
      " 1 1 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.9470588235294117 \n",
      "\n",
      "[1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 0\n",
      " 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.8522727272727273 \n",
      "\n",
      "[0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0\n",
      " 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0\n",
      " 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1\n",
      " 0 0 0 0 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.7091836734693877 \n",
      "\n",
      "[0 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0\n",
      " 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 1]\n",
      "\n",
      "end test score mean:  0.8786407766990292 \n",
      "\n",
      "[0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0\n",
      " 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0]\n",
      "\n",
      "end test score mean:  0.8636363636363636 \n",
      "\n",
      "[1 1 0 0 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.7771739130434783 \n",
      "\n",
      "[0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0\n",
      " 1 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0]\n",
      "\n",
      "end test score mean:  0.8712871287128713 \n",
      "\n",
      "[0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1]\n",
      "\n",
      "end test score mean:  0.9702380952380952 \n",
      "\n",
      "[0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0\n",
      " 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.8012048192771084 \n",
      "\n",
      "[0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0\n",
      " 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0]\n",
      "\n",
      "end test score mean:  0.9337349397590361 \n",
      "\n",
      "[0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0\n",
      " 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 1\n",
      " 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1\n",
      " 1 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.8484848484848485 \n",
      "\n",
      "[0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0]\n",
      "\n",
      "end test score mean:  0.9096385542168675 \n",
      "\n",
      "[1 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1\n",
      " 0 1 1 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0]\n",
      "\n",
      "end test score mean:  0.7294117647058823 \n",
      "\n",
      "[0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1\n",
      " 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0]\n",
      "\n",
      "end test score mean:  0.7628865979381443 \n",
      "\n",
      "[0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
      " 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0\n",
      " 1 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0\n",
      " 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.8631578947368421 \n",
      "\n",
      "[0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 1\n",
      " 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 1]\n",
      "\n",
      "end test score mean:  0.9044943820224719 \n",
      "\n",
      "0.8553262604244273 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ICA\n",
    "bci_type = 'learning'\n",
    "classifier = 'svm'\n",
    "scaling = True\n",
    "coef_of_var = False\n",
    "mutation_prob = 0.01\n",
    "num_of_generations = 100\n",
    "generation_size = 30\n",
    "\n",
    "print('bci_type:', bci_type, ', classifier:', classifier, ', scaling:', scaling, ', coef_of_var:', coef_of_var)\n",
    "print('mutation_prob:', mutation_prob, ', num_of_generations:', num_of_generations, ', generation_size:', generation_size, '\\n')\n",
    "result = []\n",
    "for i in range(50):\n",
    "    score = main(generation_size=generation_size, num_of_generations=num_of_generations, crossover_prob=1, mutation_prob=mutation_prob, \n",
    "                classifier=classifier, bci_type=bci_type, coef_of_var = False, treshold = 60,\n",
    "                scaling=scaling, downsampling=True, rand_state=4)\n",
    "    result.append(score)\n",
    "print(mean(result), '\\n')\n",
    "\n",
    "bci_type = 'withdraw'\n",
    "classifier = 'svm'\n",
    "scaling = True\n",
    "coef_of_var = False\n",
    "mutation_prob = 0.01\n",
    "num_of_generations = 100\n",
    "generation_size = 30\n",
    "\n",
    "print('bci_type:', bci_type, ', classifier:', classifier, ', scaling:', scaling, ', coef_of_var:', coef_of_var)\n",
    "print('mutation_prob:', mutation_prob, ', num_of_generations:', num_of_generations, ', generation_size:', generation_size, '\\n')\n",
    "result = []\n",
    "for i in range(51):\n",
    "    score = main(generation_size=generation_size, num_of_generations=num_of_generations, crossover_prob=1, mutation_prob=mutation_prob, \n",
    "                classifier=classifier, bci_type=bci_type, coef_of_var = False, treshold = 60,\n",
    "                scaling=scaling, downsampling=True, rand_state=4)\n",
    "    result.append(score)\n",
    "print(mean(result), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classifier: 'svm'/'knn'\n",
    "# bci_type: 'learning'/'withdraw'\n",
    "# ICA\n",
    "\n",
    "# for bci_type in ['learning','withdraw']:\n",
    "#     for classifier in ['poly2_svm']:\n",
    "#         for scaling in [True]:\n",
    "#             for coef_of_var in [False]:\n",
    "#                 for mutation_prob in [0.01]:\n",
    "#                     for num_of_generations in [100]:\n",
    "#                         for generation_size in [30]:\n",
    "#                             print('bci_type:', bci_type, ', classifier:', classifier, ', scaling:', scaling, ', coef_of_var:', coef_of_var)\n",
    "#                             print('mutation_prob:', mutation_prob, ', num_of_generations:', num_of_generations, ', generation_size:', generation_size, '\\n')\n",
    "#                             result = []\n",
    "#                             for i in range(10):\n",
    "#                                 score = main(generation_size=generation_size, num_of_generations=num_of_generations, crossover_prob=1, mutation_prob=mutation_prob, \n",
    "#                                             classifier=classifier, bci_type=bci_type, coef_of_var = False, treshold = 60,\n",
    "#                                             scaling=scaling, downsampling=True, rand_state=4)\n",
    "#                                 result.append(score)\n",
    "#                             print(mean(result), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nothing\n",
    "\n",
    "# for bci_type in ['withdraw','learning']:\n",
    "#     for classifier in ['knn','svm']:\n",
    "#         for scaling in [True]:\n",
    "#             for mutation_prob in [0.01]:\n",
    "#                 for num_of_generations in [100]:\n",
    "#                     for generation_size in [30]:\n",
    "# #                         if not (bci_type=='withdraw' and classifier=='svm' and scaling==True and mutation_prob==0.01):\n",
    "#                         print('bci_type:', bci_type, ', classifier:', classifier, ', scaling:', scaling)\n",
    "#                         print('mutation_prob:', mutation_prob, ', num_of_generations:', num_of_generations, ', generation_size:', generation_size, '\\n')\n",
    "#                         result = []\n",
    "#                         for i in range(10):\n",
    "#                             score = main2(generation_size=generation_size, num_of_generations=num_of_generations, crossover_prob=1, mutation_prob=mutation_prob, \n",
    "#                                         classifier=classifier, bci_type=bci_type, coef_of_var = False, treshold = 60,\n",
    "#                                         scaling=scaling, downsampling=True, rand_state=4)\n",
    "#                             result.append(score)\n",
    "#                         print(mean(result), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ŚMIETNIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zamiennik funkcji split_data jakbym robiła klasyfikacje wielokategorialną\n",
    "\n",
    "# rest, test = load_data()\n",
    "# n=3\n",
    "# data = \n",
    "\n",
    "# # ta funkcja potrzebna przy 3 rodzajach eventów\n",
    "# # def compensate(data, n):\n",
    "# unique, counts = np.unique(data[:,-1], return_counts=True)\n",
    "# print(counts)\n",
    "# print(min(counts))\n",
    "\n",
    "# # choose random rows\n",
    "# idx1 = np.random.randint(data[data[:,-1] == unique[0]].shape[0], size=min(counts))\n",
    "# idx2 = np.random.randint(data[data[:,-1] == unique[1]].shape[0], size=min(counts))\n",
    "# if n == 3:\n",
    "#     idx3 = np.random.randint(data[data[:,-1] == unique[2]].shape[0], size=min(counts))\n",
    "# # print(idx1)\n",
    "# # print(idx2)\n",
    "# # print(idx3)\n",
    "\n",
    "# # a = test[test[:,-1] == unique[0]]\n",
    "# print(data[data[:,-1] == unique[0]][idx1,:].shape)\n",
    "# print(data[data[:,-1] == unique[1]][idx2,:].shape)\n",
    "# if n == 3:\n",
    "#     print(data[data[:,-1] == unique[2]][idx3,:].shape)\n",
    "# dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stara funkcja split data\n",
    "\n",
    "# def split_data(df, rand_state):\n",
    "\n",
    "#     # split data to 4 groups: features and classes for errors and successful clicks\n",
    "#     X_err = df[df[:,-1] == 0][:,:-1]\n",
    "#     y_err = df[df[:,-1] == 0][:,-1]\n",
    "#     X_succ = df[df[:,-1] == 1][:,:-1]\n",
    "#     y_succ = df[df[:,-1] == 1][:,-1]\n",
    "\n",
    "#     # 20% do ostatecznego testu, wyrównana liczba przypadków w grupach\n",
    "#     X_err_rest, X_err_end_test, y_err_rest, y_err_end_test = train_test_split(X_err, y_err, test_size=0.2, random_state=rand_state)\n",
    "#     X_succ_rest, X_succ_end_test, y_succ_rest, y_succ_end_test = train_test_split(X_succ, y_succ,\n",
    "#                                                                                   test_size=y_err_end_test.shape[0],\n",
    "#                                                                                   train_size=y_err_rest.shape[0],\n",
    "#                                                                                   random_state=rand_state)\n",
    "\n",
    "#     # w tym momencie dane do ostatecznego testu wychodzą posegregowane, najpierw błędy interfejsu, potem udane kliknięcia\n",
    "#     # w k-NN to nie będzie miało znaczenia, a co w innych klasyfikatorach?\n",
    "#     X_end_test = np.concatenate((X_err_end_test, X_succ_end_test))\n",
    "#     y_end_test = np.concatenate((y_err_end_test, y_succ_end_test))\n",
    "\n",
    "#     # sklejam pozostałe 80% które wykorzystam przy cross-walidacji\n",
    "#     X_rest = np.concatenate((X_err_rest, X_succ_rest))\n",
    "#     y_rest = np.concatenate((y_err_rest, y_succ_rest))\n",
    "\n",
    "#     return X_rest, y_rest, X_end_test, y_end_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # split data to 2 groups\n",
    "# err_df = df[df['successful'] == 0]\n",
    "# succ_df = df[df['successful'] == 1]\n",
    "\n",
    "# # create features array and class array for errors\n",
    "# X_err = np.array(err_df.drop(['successful'],1))\n",
    "# y_err = np.array(err_df['successful'])\n",
    "\n",
    "# # create features array and class array for successful clicks\n",
    "# X_succ = np.array(succ_df.drop(['successful'],1))\n",
    "# y_succ = np.array(succ_df['successful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja tworząca pierwsze pokolenie\n",
    "# jedynki oznaczają cechy sygnału przekazywane do klasyfikatora\n",
    "\n",
    "# def first_gen(generation_size):\n",
    "#     first_gen = []\n",
    "#     for one in range(generation_size):\n",
    "#         ind = []\n",
    "#         for i in range(136):\n",
    "#             ind.append(randint(0, 1))\n",
    "#         first_gen.append(ind)\n",
    "#     return first_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # funkcja oceniająca przystosowanie danego osobnika\n",
    "\n",
    "# def eval(individual):\n",
    "#     features = []\n",
    "#     n_of_ones = 0\n",
    "#     for i in range(136):\n",
    "#         if individual[i] == 1:\n",
    "#             features.append(i)\n",
    "#     neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "#     neigh.fit(X_train[:, features], y_train)\n",
    "#     accuracy = neigh.score(X_test[:, features], y_test)\n",
    "#     return 136-len(features), accuracy, accuracy * (136-len(features)) - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # funkcja oceniająca całe pokolenie\n",
    "\n",
    "# def evaluation(generation):\n",
    "#     local_best_fitness = -100\n",
    "#     local_best_accuracy = 0\n",
    "#     local_n_of_zeros = 0\n",
    "#     best_individual = []\n",
    "#     gen_fitness = np.array([0])\n",
    "#     for one in generation:\n",
    "#         n_of_zeros, accuracy, fitness = eval(one)\n",
    "#         fitness = eval(one)\n",
    "#         if fitness > local_best_fitness:\n",
    "#             local_best_fitness = fitness\n",
    "#             local_best_accuracy = accuracy\n",
    "#             local_n_of_zeros = n_of_zeros\n",
    "#             best_individual = one\n",
    "#         print(fitness)\n",
    "#         np.append(gen_fitness, fitness)\n",
    "# #     return gen_fitness, local_best_fitness, best_individual\n",
    "#     return gen_fitness, local_n_of_zeros, local_best_fitness, local_best_accuracy, best_individual\n",
    "\n",
    "# f, lf, bi = evaluation(g)\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ruletka\n",
    "\n",
    "# def roulette(generation, gen_fitness):\n",
    "#     roulette_tab = []\n",
    "#     prev = 0\n",
    "#     for one in gen_fitness:\n",
    "#         prev = one/sum(gen_fitness) + prev\n",
    "#         roulette_tab.append(prev)\n",
    "#     roulette_tab[-1] = 1\n",
    "#     survivors = []\n",
    "#     for i in range(generation_size):\n",
    "#         random_num = random()\n",
    "#         winner = 0\n",
    "#         while random_num > roulette_tab[winner]:\n",
    "#             winner += 1\n",
    "#         survivors.append(generation[winner])\n",
    "#     return survivors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross2ind(ind):\n",
    "#     if np.random.rand() <= crossover_prob:\n",
    "#         cut = np.random.randint(1,135)\n",
    "#         print(cut)\n",
    "#         print(ind)\n",
    "#         idn = ind.reshape(2,136)\n",
    "#         print('reshaped: ',ind)\n",
    "#         temp = ind[1,:cut].copy()\n",
    "#         ind[1,:cut] = ind[0,:cut]\n",
    "#         ind[0,:cut] = temp\n",
    "#         idn = ind.reshape(2,136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # funkcja krzyżująca osobniki\n",
    "\n",
    "# # def crossover(survivors):\n",
    "# s = s.reshape(generation_size//2,272)\n",
    "# # print(s)\n",
    "# d = np.apply_along_axis(cross2ind, 1, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # funkcja mutująca wybrane geny wybranych osobników z pokolenia\n",
    "\n",
    "# def mutation(descendants, mutation_prob):\n",
    "#     for one in descendants:\n",
    "#         if random() <= mutation_prob:\n",
    "#             locus = randint(0,135)\n",
    "# #             zamiana genu\n",
    "#             one[locus] = 1 - one[locus]\n",
    "#     return descendants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
